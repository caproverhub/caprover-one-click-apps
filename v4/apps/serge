{"captainVersion":4,"services":{"$$cap_appname":{"image":"ghcr.io/serge-chat/serge:$$cap_myapp_version","volumes":["$$cap_appname-db:/data/db","$$cap_appname-weights:/usr/src/app/weights/"],"caproverExtra":{"containerHttpPort":"8008"}}},"caproverOneClickApp":{"variables":[{"id":"$$cap_myapp_version","label":"Serge version","defaultValue":"0.8.2","description":"Check out their GitHub page for the valid tags https://github.com/serge-chat/serge/pkgs/container/serge","validRegex":"/.{1,}/"}],"instructions":{"start":"A web interface for chatting with Alpaca through llama.cpp. Fully dockerized, with an easy to use API.\nPrefer CPU with AVX2 enable: `lscpu | grep avx2`","end":"Done! ðŸš€"},"displayName":"Serge LLaMa (AI)","isOfficial":true,"description":"Serge is a chat interface crafted with llama.cpp for running GGUF models. No API keys, entirely self-hosted!","documentation":"This docker-compose is taken from https://github.com/serge-chat/serge"}}
